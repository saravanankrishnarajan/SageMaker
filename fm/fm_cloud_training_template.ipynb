{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9cab06",
   "metadata": {},
   "source": [
    "### Factorization Machines - Movie Recommendation Model\n",
    "Input features: ['userId','movieId']\n",
    "Target: rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9053244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a7975",
   "metadata": {},
   "source": [
    "#### Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9093d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import s3 bucket name as environment variable\n",
    "\n",
    "import os\n",
    "env_vars = !cat ./.env\n",
    "for var in env_vars:\n",
    "    key, value = var.split('=')\n",
    "    os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce804820",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = os.environ['BUCKET_NAME']\n",
    "training_file_key = 'movie/user_movie_train.recordio'\n",
    "test_file_key = 'movie/user_movie_test.recordio'\n",
    "\n",
    "s3_model_output_location = r's3://{}/movie/model'.format(bucket_name)\n",
    "s3_training_file_location = r's3://{}/{}'.format(bucket_name,training_file_key)\n",
    "s3_test_file_location = r's3://{}/{}'.format(bucket_name, test_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc30287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dimension:Number of unique users + number of unique movies in our dataset\n",
    "\n",
    "dim_movie = 0\n",
    "\n",
    "#Update movie dimension - from file used for training\n",
    "with open(r'ml-latest-small/movie_dimension.txt') as f:\n",
    "    dim_movie= int(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06492b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78984846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and Reading from S3\n",
    "# files are referred as objects in S3.  \n",
    "# file name is referred as key name in S3\n",
    "# Files stored in S3 are automatically replicated across 3 different availability zones \n",
    "# in the region where the bucket was created.\n",
    "\n",
    "def write_to_s3(filename,bucket,key):\n",
    "    with open(filename, 'rb') as f:\n",
    "        boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f684ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3(r'ml-latest-small/user_movie_train.recordio',bucket_name,training_file_key)\n",
    "write_to_s3(r'ml-latest-small/user_movie_test.recordio',bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b0d026",
   "metadata": {},
   "source": [
    "### Training Algorithm Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b129cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use spot instance for traing\n",
    "\n",
    "use_spot_instances = True\n",
    "max_run = 3600\n",
    "max_wait = 3600\n",
    "\n",
    "job_name = 'fm-movie-v4'\n",
    "\n",
    "checkpoint_s3_uri = None\n",
    "\n",
    "if use_spot_instances:\n",
    "    checkpoint_s3_uri = f's3://{bucket_name}/movie/checkpoints/{job_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a00f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.session.Session at 0x7f391ebda590>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee90d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd004445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using FM container 382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:1\n"
     ]
    }
   ],
   "source": [
    "# Use fatorization-machines\n",
    "\n",
    "container = sagemaker.image_uris.retrieve(\"factorization-machines\",sess.boto_region_name)\n",
    "print(f'using FM container {container}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c893096",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff2d363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training job\n",
    "# specify type and number of instances to use\n",
    "# s3 location where final artifacts needs tobe stored\n",
    "\n",
    "# SDK 2.x version does not require train prefix for instance count and type\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(container,\n",
    "                                          role,\n",
    "                                          instance_count=1,\n",
    "                                          instance_type='ml.m5.xlarge',\n",
    "                                          output_path=s3_model_output_location,\n",
    "                                          sagemaker_session=sess,\n",
    "                                          base_job_name=job_name,\n",
    "                                          use_spot_instances=use_spot_instances,\n",
    "                                          max_run=max_run,\n",
    "                                          max_wait=max_wait,\n",
    "                                          checkpoint_s3_uri=checkpoint_s3_uri\n",
    "                                    \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53fdd9",
   "metadata": {},
   "source": [
    "#### New Configuration after Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51240d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(feature_dim=dim_movie,\n",
    "                             num_factors=8,\n",
    "                              predictor_type='regressor',\n",
    "                              mini_batch_size=994,\n",
    "                              epochs=91,\n",
    "                              bias_init_method='normal',\n",
    "                              bias_lr=0.21899531189430518,\n",
    "                              factors_init_method='normal',\n",
    "                              factors_lr=5.357593337770278e-05,\n",
    "                              linear_init_method='normal',\n",
    "                              linear_lr=0.00021524948053767607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35a75aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_dim': 10334,\n",
       " 'num_factors': 8,\n",
       " 'predictor_type': 'regressor',\n",
       " 'mini_batch_size': 994,\n",
       " 'epochs': 91,\n",
       " 'bias_init_method': 'normal',\n",
       " 'bias_lr': 0.21899531189430518,\n",
       " 'factors_init_method': 'normal',\n",
       " 'factors_lr': 5.357593337770278e-05,\n",
       " 'linear_init_method': 'normal',\n",
       " 'linear_lr': 0.00021524948053767607}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8bea3",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f8b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: fm-movie-v4-2024-05-15-21-26-16-668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-15 21:26:16 Starting - Starting the training job...\n",
      "2024-05-15 21:26:31 Starting - Preparing the instances for training...\n",
      "2024-05-15 21:27:00 Downloading - Downloading input data...\n",
      "2024-05-15 21:27:20 Downloading - Downloading the training image..................\n",
      "2024-05-15 21:30:36 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'bias_init_method': 'normal', 'bias_lr': '0.21899531189430518', 'epochs': '91', 'factors_init_method': 'normal', 'factors_lr': '5.357593337770278e-05', 'feature_dim': '10334', 'linear_init_method': 'normal', 'linear_lr': '0.00021524948053767607', 'mini_batch_size': '994', 'num_factors': '8', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] Final configuration: {'epochs': '91', 'mini_batch_size': '994', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.21899531189430518', 'linear_lr': '0.00021524948053767607', 'factors_lr': '5.357593337770278e-05', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '10334', 'num_factors': '8', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 WARNING 140500196235072] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:46.317] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:46.323] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 13, \"num_examples\": 1, \"num_bytes\": 63616}\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808646.309043, \"EndTime\": 1715808646.3611295, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 40.56692123413086, \"count\": 1, \"min\": 40.56692123413086, \"max\": 40.56692123413086}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808646.3612573, \"EndTime\": 1715808646.361287, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 994.0, \"count\": 1, \"min\": 994, \"max\": 994}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 994.0, \"count\": 1, \"min\": 994, \"max\": 994}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[21:30:46] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.404.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[21:30:46] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.404.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[21:30:46] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.404.0/AL2_x86_64/generic-flavor/src/src/operator/././../common/utils.h:450: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=3.646887842133151\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=13.299790933098592\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=3.500805369325327\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:46.692] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 316, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.5197361996021286\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #quality_metric: host=algo-1, epoch=0, train mse <loss>=2.309598116381121\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.1554540220107539\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808646.3612068, \"EndTime\": 1715808646.6939127, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"update.time\": {\"sum\": 332.37385749816895, \"count\": 1, \"min\": 332.37385749816895, \"max\": 332.37385749816895}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #progress_metric: host=algo-1, completed 1.098901098901099 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808646.361511, \"EndTime\": 1715808646.6942644, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 71579.0, \"count\": 1, \"min\": 71579, \"max\": 71579}, \"Total Batches Seen\": {\"sum\": 73.0, \"count\": 1, \"min\": 73, \"max\": 73}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=212045.64426634007 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.0234240604966414\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.047396807603433\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:46 INFO 140500196235072] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=0.8189823756995096\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:47.038] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 341, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.1155756837454913\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.2445091061642206\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.8795603712266546\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808646.6940143, \"EndTime\": 1715808647.0394444, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 344.6969985961914, \"count\": 1, \"min\": 344.6969985961914, \"max\": 344.6969985961914}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #progress_metric: host=algo-1, completed 2.197802197802198 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808646.6947212, \"EndTime\": 1715808647.0398679, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 142164.0, \"count\": 1, \"min\": 142164, \"max\": 142164}, \"Total Batches Seen\": {\"sum\": 145.0, \"count\": 1, \"min\": 145, \"max\": 145}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=204304.04449689115 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.0251199438229002\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.0508708992234659\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.82658352458501\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:47.387] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 343, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.1164356710480259\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.246428607588456\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.8795249362453476\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808647.0395527, \"EndTime\": 1715808647.3892567, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 348.68764877319336, \"count\": 1, \"min\": 348.68764877319336, \"max\": 348.68764877319336}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #progress_metric: host=algo-1, completed 3.2967032967032965 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808647.0405405, \"EndTime\": 1715808647.389942, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 212749.0, \"count\": 1, \"min\": 212749, \"max\": 212749}, \"Total Batches Seen\": {\"sum\": 217.0, \"count\": 1, \"min\": 217, \"max\": 217}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=201780.20797224675 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.0249226177880313\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.0504663724534709\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.8286705093844315\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:47.739] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 345, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.1143875756921624\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.2418596688570551\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.877086690573945\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808647.3895557, \"EndTime\": 1715808647.7398863, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 349.1480350494385, \"count\": 1, \"min\": 349.1480350494385, \"max\": 349.1480350494385}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #progress_metric: host=algo-1, completed 4.395604395604396 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808647.3907115, \"EndTime\": 1715808647.740127, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 283334.0, \"count\": 1, \"min\": 283334, \"max\": 283334}, \"Total Batches Seen\": {\"sum\": 289.0, \"count\": 1, \"min\": 289, \"max\": 289}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=201927.1927303333 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.0248812188293173\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.050381512709067\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:47 INFO 140500196235072] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.8302560111646441\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:48.077] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 334, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.1115614940453293\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.2355689550442848\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.8743470121810507\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808647.7399666, \"EndTime\": 1715808648.0781076, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 337.5828266143799, \"count\": 1, \"min\": 337.5828266143799, \"max\": 337.5828266143799}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #progress_metric: host=algo-1, completed 5.4945054945054945 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808647.7404313, \"EndTime\": 1715808648.0784652, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 353919.0, \"count\": 1, \"min\": 353919, \"max\": 353919}, \"Total Batches Seen\": {\"sum\": 361.0, \"count\": 1, \"min\": 361, \"max\": 361}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=208710.89800231653 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.0236996550138573\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.0479609836754904\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.8298427036830357\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:48.425] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 344, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.1083176315578191\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.2283679724219339\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.8714153077440883\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808648.078175, \"EndTime\": 1715808648.426343, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 347.36037254333496, \"count\": 1, \"min\": 347.36037254333496, \"max\": 347.36037254333496}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #progress_metric: host=algo-1, completed 6.593406593406593 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808648.0789537, \"EndTime\": 1715808648.4266899, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 424504.0, \"count\": 1, \"min\": 424504, \"max\": 424504}, \"Total Batches Seen\": {\"sum\": 433.0, \"count\": 1, \"min\": 433, \"max\": 433}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=202897.9885575808 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.021472198468817\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.0434054522447183\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.827937350666499\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:48.773] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 344, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.1048948934682883\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.2207927256123001\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.8683295408778081\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808648.4264402, \"EndTime\": 1715808648.7743506, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 347.261905670166, \"count\": 1, \"min\": 347.261905670166, \"max\": 347.261905670166}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #progress_metric: host=algo-1, completed 7.6923076923076925 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808648.427063, \"EndTime\": 1715808648.7745116, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 495089.0, \"count\": 1, \"min\": 495089, \"max\": 495089}, \"Total Batches Seen\": {\"sum\": 505.0, \"count\": 1, \"min\": 505, \"max\": 505}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=203095.35878780062 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=1.018587458468458\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=1.0375204105492328\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:48 INFO 140500196235072] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.8251580405283262\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:49.147] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 370, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.1014064001742032\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.213096058344697\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.8651623255769971\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808648.7744126, \"EndTime\": 1715808649.148297, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 373.5339641571045, \"count\": 1, \"min\": 373.5339641571045, \"max\": 373.5339641571045}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #progress_metric: host=algo-1, completed 8.791208791208792 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808648.7747343, \"EndTime\": 1715808649.1485565, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 565674.0, \"count\": 1, \"min\": 565674, \"max\": 565674}, \"Total Batches Seen\": {\"sum\": 577.0, \"count\": 1, \"min\": 577, \"max\": 577}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=188757.46543223495 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=1.0153375376730998\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=1.0309103154080734\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.8218921684403295\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:49.496] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 345, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.097900645645606\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.2053858277090386\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.8619507223121171\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808649.1483948, \"EndTime\": 1715808649.4973323, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 348.4780788421631, \"count\": 1, \"min\": 348.4780788421631, \"max\": 348.4780788421631}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #progress_metric: host=algo-1, completed 9.89010989010989 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808649.1488278, \"EndTime\": 1715808649.4974885, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 636259.0, \"count\": 1, \"min\": 636259, \"max\": 636259}, \"Total Batches Seen\": {\"sum\": 649.0, \"count\": 1, \"min\": 649, \"max\": 649}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=202387.28084363425 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=1.0118971849157024\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=1.0239359128403231\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.8183543399066273\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:49.783] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 284, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.0944008632151678\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.1977132494061047\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.8587238960769281\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808649.4973936, \"EndTime\": 1715808649.7842824, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.6051197052002, \"count\": 1, \"min\": 286.6051197052002, \"max\": 286.6051197052002}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #progress_metric: host=algo-1, completed 10.989010989010989 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808649.4976544, \"EndTime\": 1715808649.7844708, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 706844.0, \"count\": 1, \"min\": 706844, \"max\": 706844}, \"Total Batches Seen\": {\"sum\": 721.0, \"count\": 1, \"min\": 721, \"max\": 721}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=246022.97713989878 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=1.0083672757125401\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=1.01680456272793\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:49 INFO 140500196235072] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.8146637392715669\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:50.069] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 282, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=1.0909204291235222\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=10, train mse <loss>=1.1901073826790496\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.8554959347283789\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808649.7843673, \"EndTime\": 1715808650.070154, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 285.4921817779541, \"count\": 1, \"min\": 285.4921817779541, \"max\": 285.4921817779541}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #progress_metric: host=algo-1, completed 12.087912087912088 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808649.784634, \"EndTime\": 1715808650.0706336, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 777429.0, \"count\": 1, \"min\": 777429, \"max\": 777429}, \"Total Batches Seen\": {\"sum\": 793.0, \"count\": 1, \"min\": 793, \"max\": 793}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=246685.32114800706 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=1.0048066333722658\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=1.009636370468907\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.8108884631028358\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:50.355] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 281, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=1.0874684160975043\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=11, train mse <loss>=1.1825875560096146\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.8522780597702971\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808650.0702217, \"EndTime\": 1715808650.3559334, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.69038009643555, \"count\": 1, \"min\": 284.69038009643555, \"max\": 284.69038009643555}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #progress_metric: host=algo-1, completed 13.186813186813186 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808650.0712152, \"EndTime\": 1715808650.356145, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 848014.0, \"count\": 1, \"min\": 848014, \"max\": 848014}, \"Total Batches Seen\": {\"sum\": 865.0, \"count\": 1, \"min\": 865, \"max\": 865}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=247617.91270077584 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=1.0012504389043981\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=1.00250244140625\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.8070690991653043\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:50.663] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 305, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=1.0840516296352656\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=12, train mse <loss>=1.1751679357148752\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.8490731435255958\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808650.3560042, \"EndTime\": 1715808650.663785, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 307.33227729797363, \"count\": 1, \"min\": 307.33227729797363, \"max\": 307.33227729797363}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #progress_metric: host=algo-1, completed 14.285714285714286 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808650.356427, \"EndTime\": 1715808650.6639986, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 918599.0, \"count\": 1, \"min\": 918599, \"max\": 918599}, \"Total Batches Seen\": {\"sum\": 937.0, \"count\": 1, \"min\": 937, \"max\": 937}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=229396.10892433193 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=0.997720188145768\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=0.9954455738336268\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.8032308229258363\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:50.935] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 269, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=1.080675325879457\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=13, train mse <loss>=1.1678591599646708\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.8458918795978999\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808650.6638577, \"EndTime\": 1715808650.9364808, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 272.1986770629883, \"count\": 1, \"min\": 272.1986770629883, \"max\": 272.1986770629883}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #progress_metric: host=algo-1, completed 15.384615384615385 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808650.6642563, \"EndTime\": 1715808650.9366817, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 989184.0, \"count\": 1, \"min\": 989184, \"max\": 989184}, \"Total Batches Seen\": {\"sum\": 1009.0, \"count\": 1, \"min\": 1009, \"max\": 1009}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=258988.73856527623 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=0.9942294359399421\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=0.9884921712894554\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:50 INFO 140500196235072] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.7993898449289487\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:51.226] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 287, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=1.077343775774561\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=14, train mse <loss>=1.1606696112001873\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.8427363557088516\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808650.9365535, \"EndTime\": 1715808651.2267253, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 289.7958755493164, \"count\": 1, \"min\": 289.7958755493164, \"max\": 289.7958755493164}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #progress_metric: host=algo-1, completed 16.483516483516482 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808650.9369037, \"EndTime\": 1715808651.2269447, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1059769.0, \"count\": 1, \"min\": 1059769, \"max\": 1059769}, \"Total Batches Seen\": {\"sum\": 1081.0, \"count\": 1, \"min\": 1081, \"max\": 1081}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=243276.18048399687 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=0.9907870283501268\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=0.981658935546875\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.795578340649365\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:51.518] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 289, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=1.0740602951512663\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=15, train mse <loss>=1.1536055176204252\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.8396096147468579\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808651.2267935, \"EndTime\": 1715808651.5194752, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 292.03128814697266, \"count\": 1, \"min\": 292.03128814697266, \"max\": 292.03128814697266}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #progress_metric: host=algo-1, completed 17.582417582417584 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808651.2274203, \"EndTime\": 1715808651.5197077, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1130354.0, \"count\": 1, \"min\": 1130354, \"max\": 1130354}, \"Total Batches Seen\": {\"sum\": 1153.0, \"count\": 1, \"min\": 1153, \"max\": 1153}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=241412.84113824597 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=0.9873985392884947\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=0.974955875389053\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.7918195206394618\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:51.822] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 299, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=1.0708276131168524\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=16, train mse <loss>=1.1466717770135353\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.836511782930384\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808651.519579, \"EndTime\": 1715808651.8225706, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 302.42180824279785, \"count\": 1, \"min\": 302.42180824279785, \"max\": 302.42180824279785}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #progress_metric: host=algo-1, completed 18.681318681318682 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808651.5201232, \"EndTime\": 1715808651.8228083, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1200939.0, \"count\": 1, \"min\": 1200939, \"max\": 1200939}, \"Total Batches Seen\": {\"sum\": 1225.0, \"count\": 1, \"min\": 1225, \"max\": 1225}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=233108.07501852314 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=0.9840678016232671\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=0.9683894381916499\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:51 INFO 140500196235072] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.7880852620606451\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:52.108] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 282, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=1.0676478214379697\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=17, train mse <loss>=1.1398718706212427\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.8334454042437677\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808651.8226423, \"EndTime\": 1715808652.1087148, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 285.4137420654297, \"count\": 1, \"min\": 285.4137420654297, \"max\": 285.4137420654297}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #progress_metric: host=algo-1, completed 19.78021978021978 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808651.8232758, \"EndTime\": 1715808652.1088822, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1271524.0, \"count\": 1, \"min\": 1271524, \"max\": 1271524}, \"Total Batches Seen\": {\"sum\": 1297.0, \"count\": 1, \"min\": 1297, \"max\": 1297}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=247062.25551009303 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=0.9807970940759675\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=0.9619629397478622\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.7844097053021253\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:52.398] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 287, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=1.0645224832202624\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=18, train mse <loss>=1.133208117281434\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.8304129484753574\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808652.1087782, \"EndTime\": 1715808652.3988068, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 289.5069122314453, \"count\": 1, \"min\": 289.5069122314453, \"max\": 289.5069122314453}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #progress_metric: host=algo-1, completed 20.87912087912088 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808652.1092749, \"EndTime\": 1715808652.399016, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1342109.0, \"count\": 1, \"min\": 1342109, \"max\": 1342109}, \"Total Batches Seen\": {\"sum\": 1369.0, \"count\": 1, \"min\": 1369, \"max\": 1369}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=243514.90292879252 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=0.9775879299385011\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=0.9556781607614436\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.7807944468569228\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:52.686] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 285, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=1.061452862025449\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=19, train mse <loss>=1.126682178302017\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.827415849228127\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808652.3988757, \"EndTime\": 1715808652.6875613, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 288.01989555358887, \"count\": 1, \"min\": 288.01989555358887, \"max\": 288.01989555358887}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #progress_metric: host=algo-1, completed 21.978021978021978 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808652.3995142, \"EndTime\": 1715808652.6877983, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1412694.0, \"count\": 1, \"min\": 1412694, \"max\": 1412694}, \"Total Batches Seen\": {\"sum\": 1441.0, \"count\": 1, \"min\": 1441, \"max\": 1441}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 21.0, \"count\": 1, \"min\": 21, \"max\": 21}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=244741.0672367414 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=0.9744412638387956\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=0.9495357766717493\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.777328828930615\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:52.978] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 288, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=1.0584396851427709\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=20, train mse <loss>=1.1202945670851279\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.8244568304330104\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808652.6876369, \"EndTime\": 1715808652.9792342, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 290.9364700317383, \"count\": 1, \"min\": 290.9364700317383, \"max\": 290.9364700317383}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #progress_metric: host=algo-1, completed 23.076923076923077 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808652.6882718, \"EndTime\": 1715808652.9794781, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1483279.0, \"count\": 1, \"min\": 1483279, \"max\": 1483279}, \"Total Batches Seen\": {\"sum\": 1513.0, \"count\": 1, \"min\": 1513, \"max\": 1513}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 22.0, \"count\": 1, \"min\": 22, \"max\": 22}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=242294.61799849413 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=0.9713573554770788\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=0.9435351120394241\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:52 INFO 140500196235072] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.7739536584742832\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:53.303] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 321, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=1.0554835188009322\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=21, train mse <loss>=1.1140454584603978\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.8215354690875832\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808652.979306, \"EndTime\": 1715808653.3039987, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 324.0349292755127, \"count\": 1, \"min\": 324.0349292755127, \"max\": 324.0349292755127}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #progress_metric: host=algo-1, completed 24.175824175824175 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808652.9799376, \"EndTime\": 1715808653.3041975, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1553864.0, \"count\": 1, \"min\": 1553864, \"max\": 1553864}, \"Total Batches Seen\": {\"sum\": 1585.0, \"count\": 1, \"min\": 1585, \"max\": 1585}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=217605.85944976515 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=0.9683363605764167\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=0.9376753072143801\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.7706397687885124\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:53.606] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 300, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=1.0525846573934177\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=22, train mse <loss>=1.1079344609800186\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.8186551449471023\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808653.3040674, \"EndTime\": 1715808653.6072285, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 302.5329113006592, \"count\": 1, \"min\": 302.5329113006592, \"max\": 302.5329113006592}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #progress_metric: host=algo-1, completed 25.274725274725274 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808653.3046713, \"EndTime\": 1715808653.6074932, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1624449.0, \"count\": 1, \"min\": 1624449, \"max\": 1624449}, \"Total Batches Seen\": {\"sum\": 1657.0, \"count\": 1, \"min\": 1657, \"max\": 1657}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 24.0, \"count\": 1, \"min\": 24, \"max\": 24}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=233008.08595772946 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=0.96537797928917\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=0.9319546428964411\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.7674092037577025\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:53.882] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 273, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=1.0497430630281512\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=23, train mse <loss>=1.1019604983757252\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.8158205894983617\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808653.6073017, \"EndTime\": 1715808653.8832731, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.3140926361084, \"count\": 1, \"min\": 275.3140926361084, \"max\": 275.3140926361084}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #progress_metric: host=algo-1, completed 26.373626373626372 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808653.6079357, \"EndTime\": 1715808653.8834314, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1695034.0, \"count\": 1, \"min\": 1695034, \"max\": 1695034}, \"Total Batches Seen\": {\"sum\": 1729.0, \"count\": 1, \"min\": 1729, \"max\": 1729}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 25.0, \"count\": 1, \"min\": 25, \"max\": 25}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=256124.38746157766 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=0.9624820553149653\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=0.9263717068033199\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:53 INFO 140500196235072] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.7643423406650842\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:54.161] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 276, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=1.0469586981824734\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=24, train mse <loss>=1.0961225156999397\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.8130323630490081\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808653.8833306, \"EndTime\": 1715808654.1624095, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.4092426300049, \"count\": 1, \"min\": 278.4092426300049, \"max\": 278.4092426300049}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #progress_metric: host=algo-1, completed 27.47252747252747 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808653.8839767, \"EndTime\": 1715808654.1626027, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1765619.0, \"count\": 1, \"min\": 1765619, \"max\": 1765619}, \"Total Batches Seen\": {\"sum\": 1801.0, \"count\": 1, \"min\": 1801, \"max\": 1801}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 26.0, \"count\": 1, \"min\": 26, \"max\": 26}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=253238.62698287106 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=0.9596478103891825\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=0.9209239199847523\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.7614038724534709\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:54.443] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 278, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=1.044231264383609\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=25, train mse <loss>=1.0904189335161905\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.8102913806829147\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808654.1624694, \"EndTime\": 1715808654.4444141, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 281.3732624053955, \"count\": 1, \"min\": 281.3732624053955, \"max\": 281.3732624053955}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #progress_metric: host=algo-1, completed 28.571428571428573 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808654.163014, \"EndTime\": 1715808654.444679, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1836204.0, \"count\": 1, \"min\": 1836204, \"max\": 1836204}, \"Total Batches Seen\": {\"sum\": 1873.0, \"count\": 1, \"min\": 1873, \"max\": 1873}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 27.0, \"count\": 1, \"min\": 27, \"max\": 27}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=250499.59287833225 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=0.9568745412546031\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=0.9156088877012073\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.7586485711141852\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:54.718] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 271, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=1.0415602557903847\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=26, train mse <loss>=1.0848477664421314\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.8076024037358374\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808654.444487, \"EndTime\": 1715808654.7194717, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 274.29747581481934, \"count\": 1, \"min\": 274.29747581481934, \"max\": 274.29747581481934}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #progress_metric: host=algo-1, completed 29.67032967032967 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808654.4451487, \"EndTime\": 1715808654.7196712, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1906789.0, \"count\": 1, \"min\": 1906789, \"max\": 1906789}, \"Total Batches Seen\": {\"sum\": 1945.0, \"count\": 1, \"min\": 1945, \"max\": 1945}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=257021.1463446396 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=0.9541618142879925\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=0.9104247678453534\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.7560096909582495\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:54.993] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 271, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=1.0389452875529497\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=27, train mse <loss>=1.0794073105284812\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.8049677442230423\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808654.7195392, \"EndTime\": 1715808654.9938903, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 273.78273010253906, \"count\": 1, \"min\": 273.78273010253906, \"max\": 273.78273010253906}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #progress_metric: host=algo-1, completed 30.76923076923077 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808654.720081, \"EndTime\": 1715808654.994115, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1977374.0, \"count\": 1, \"min\": 1977374, \"max\": 1977374}, \"Total Batches Seen\": {\"sum\": 2017.0, \"count\": 1, \"min\": 2017, \"max\": 2017}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 29.0, \"count\": 1, \"min\": 29, \"max\": 29}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:54 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=257473.56414685096 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=0.9515083403821737\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=0.9053681218168386\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.753450205628301\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-15 21:30:55.270] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 273, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=1.036385629770208\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=28, train mse <loss>=1.074095173594191\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.8023887513175844\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808654.9939668, \"EndTime\": 1715808655.2704835, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 275.8975028991699, \"count\": 1, \"min\": 275.8975028991699, \"max\": 275.8975028991699}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #progress_metric: host=algo-1, completed 31.86813186813187 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808654.994563, \"EndTime\": 1715808655.270638, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2047959.0, \"count\": 1, \"min\": 2047959, \"max\": 2047959}, \"Total Batches Seen\": {\"sum\": 2089.0, \"count\": 1, \"min\": 2089, \"max\": 2089}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=255589.06475217643 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=0.9489134841967641\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=0.9004368004904426\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.7509918519908514\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:55.554] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 281, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=1.033880644828907\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=29, train mse <loss>=1.0689091877518366\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.7998662966091361\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808655.2705424, \"EndTime\": 1715808655.5551698, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.313440322876, \"count\": 1, \"min\": 284.313440322876, \"max\": 284.313440322876}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #progress_metric: host=algo-1, completed 32.967032967032964 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808655.2708108, \"EndTime\": 1715808655.555602, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2118544.0, \"count\": 1, \"min\": 2118544, \"max\": 2118544}, \"Total Batches Seen\": {\"sum\": 2161.0, \"count\": 1, \"min\": 2161, \"max\": 2161}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=247747.62870862085 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=0.946376203154968\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=0.8956279178980131\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.7486017177282445\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:55.838] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 280, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=1.0314295185122702\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=30, train mse <loss>=1.0638468516584534\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.797399377172595\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808655.5552359, \"EndTime\": 1715808655.8397365, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.7386131286621, \"count\": 1, \"min\": 283.7386131286621, \"max\": 283.7386131286621}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #progress_metric: host=algo-1, completed 34.065934065934066 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808655.555947, \"EndTime\": 1715808655.8400233, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 30, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2189129.0, \"count\": 1, \"min\": 2189129, \"max\": 2189129}, \"Total Batches Seen\": {\"sum\": 2233.0, \"count\": 1, \"min\": 2233, \"max\": 2233}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 32.0, \"count\": 1, \"min\": 32, \"max\": 32}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=248380.33045232066 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=0.9438954002789819\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=0.8909385266678194\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:55 INFO 140500196235072] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.7462684431786029\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:56.122] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 280, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=1.029031407042855\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=31, train mse <loss>=1.058905636680598\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.7949891400609058\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808655.8398077, \"EndTime\": 1715808656.1229317, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.5934886932373, \"count\": 1, \"min\": 282.5934886932373, \"max\": 282.5934886932373}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #progress_metric: host=algo-1, completed 35.16483516483517 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808655.8403122, \"EndTime\": 1715808656.1231034, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 31, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2259714.0, \"count\": 1, \"min\": 2259714, \"max\": 2259714}, \"Total Batches Seen\": {\"sum\": 2305.0, \"count\": 1, \"min\": 2305, \"max\": 2305}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=249516.81763284517 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=0.9414703154467942\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=0.8863663548674862\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.7439898792167065\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:56.447] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 322, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=1.0266855538765831\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=32, train mse <loss>=1.0540832265388664\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.7926374180002977\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808656.1230052, \"EndTime\": 1715808656.447967, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 324.6586322784424, \"count\": 1, \"min\": 324.6586322784424, \"max\": 324.6586322784424}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #progress_metric: host=algo-1, completed 36.26373626373626 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808656.1232843, \"EndTime\": 1715808656.448171, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 32, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2330299.0, \"count\": 1, \"min\": 2330299, \"max\": 2330299}, \"Total Batches Seen\": {\"sum\": 2377.0, \"count\": 1, \"min\": 2377, \"max\": 2377}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 34.0, \"count\": 1, \"min\": 34, \"max\": 34}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=217185.38015059303 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=0.9390995495136079\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=0.8819079638966613\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.7417611749599158\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:56.746] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 295, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=1.0243909493628607\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=33, train mse <loss>=1.0493768171365432\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.7903423714419219\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808656.448036, \"EndTime\": 1715808656.7466316, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 298.1865406036377, \"count\": 1, \"min\": 298.1865406036377, \"max\": 298.1865406036377}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #progress_metric: host=algo-1, completed 37.362637362637365 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808656.4484203, \"EndTime\": 1715808656.7468345, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 33, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2400884.0, \"count\": 1, \"min\": 2400884, \"max\": 2400884}, \"Total Batches Seen\": {\"sum\": 2449.0, \"count\": 1, \"min\": 2449, \"max\": 2449}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 35.0, \"count\": 1, \"min\": 35, \"max\": 35}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=236438.98557750284 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=0.9367822039365585\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=0.8775608976122359\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:56 INFO 140500196235072] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.7395937514736859\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:57.025] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 275, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=1.0221466545807802\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=34, train mse <loss>=1.0447837834706808\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.7881022085952674\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808656.7466962, \"EndTime\": 1715808657.025511, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 278.40304374694824, \"count\": 1, \"min\": 278.40304374694824, \"max\": 278.40304374694824}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #progress_metric: host=algo-1, completed 38.46153846153846 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808656.7470841, \"EndTime\": 1715808657.0256698, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 34, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2471469.0, \"count\": 1, \"min\": 2471469, \"max\": 2471469}, \"Total Batches Seen\": {\"sum\": 2521.0, \"count\": 1, \"min\": 2521, \"max\": 2521}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 36.0, \"count\": 1, \"min\": 36, \"max\": 36}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=253275.2401305152 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=0.9345170991707321\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=0.8733222086424799\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.7374591174979565\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:57.310] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 282, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=1.0199518356302273\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=35, train mse <loss>=1.0403017470054703\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.7859172390367051\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808657.025571, \"EndTime\": 1715808657.3107047, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.8355770111084, \"count\": 1, \"min\": 284.8355770111084, \"max\": 284.8355770111084}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #progress_metric: host=algo-1, completed 39.56043956043956 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808657.0258439, \"EndTime\": 1715808657.3109384, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 35, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2542054.0, \"count\": 1, \"min\": 2542054, \"max\": 2542054}, \"Total Batches Seen\": {\"sum\": 2593.0, \"count\": 1, \"min\": 2593, \"max\": 2593}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=247491.4358276007 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=0.9323031011547791\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=0.8691890724228182\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.7353585625078597\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:57.594] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 281, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=1.017805385207667\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=36, train mse <loss>=1.0359278021577272\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.783783376017007\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808657.3107748, \"EndTime\": 1715808657.5951, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.9021682739258, \"count\": 1, \"min\": 283.9021682739258, \"max\": 283.9021682739258}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #progress_metric: host=algo-1, completed 40.65934065934066 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808657.3111744, \"EndTime\": 1715808657.5952559, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 36, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2612639.0, \"count\": 1, \"min\": 2612639, \"max\": 2612639}, \"Total Batches Seen\": {\"sum\": 2665.0, \"count\": 1, \"min\": 2665, \"max\": 2665}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 38.0, \"count\": 1, \"min\": 38, \"max\": 38}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=248384.49818025006 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=0.9301392215182437\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=0.8651589714065644\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.7332794373663858\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:57.877] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 280, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=1.0157063421031185\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=37, train mse <loss>=1.0316593733884971\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.7817019277735096\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808657.595159, \"EndTime\": 1715808657.8788059, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.3409309387207, \"count\": 1, \"min\": 283.3409309387207, \"max\": 283.3409309387207}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #progress_metric: host=algo-1, completed 41.75824175824176 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808657.5954409, \"EndTime\": 1715808657.8789937, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 37, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2683224.0, \"count\": 1, \"min\": 2683224, \"max\": 2683224}, \"Total Batches Seen\": {\"sum\": 2737.0, \"count\": 1, \"min\": 2737, \"max\": 2737}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 39.0, \"count\": 1, \"min\": 39, \"max\": 39}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=248835.2283942264 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=0.9280242228638153\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=0.8612289582219882\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:57 INFO 140500196235072] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.7312380754252075\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:58.156] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 275, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=1.0136537455465822\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=38, train mse <loss>=1.0274939158606151\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.779673009437921\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808657.8788645, \"EndTime\": 1715808658.157098, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 277.85205841064453, \"count\": 1, \"min\": 277.85205841064453, \"max\": 277.85205841064453}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #progress_metric: host=algo-1, completed 42.857142857142854 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808657.8792183, \"EndTime\": 1715808658.1573036, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 38, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2753809.0, \"count\": 1, \"min\": 2753809, \"max\": 2753809}, \"Total Batches Seen\": {\"sum\": 2809.0, \"count\": 1, \"min\": 2809, \"max\": 2809}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 40.0, \"count\": 1, \"min\": 40, \"max\": 40}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=253726.7320405956 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=0.9259569149288289\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=0.8573962083045146\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.7292312222947057\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:58.443] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 283, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=1.011646545877785\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=39, train mse <loss>=1.0234287337864536\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.7776933273905586\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808658.1571658, \"EndTime\": 1715808658.4437826, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.2122058868408, \"count\": 1, \"min\": 286.2122058868408, \"max\": 286.2122058868408}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #progress_metric: host=algo-1, completed 43.956043956043956 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808658.15753, \"EndTime\": 1715808658.4440079, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 39, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2824394.0, \"count\": 1, \"min\": 2824394, \"max\": 2824394}, \"Total Batches Seen\": {\"sum\": 2881.0, \"count\": 1, \"min\": 2881, \"max\": 2881}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 41.0, \"count\": 1, \"min\": 41, \"max\": 41}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=246279.82497412877 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=0.9239362886644484\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=0.853658265511035\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.7272519393705986\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:58.747] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 301, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=1.0096837523553426\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=40, train mse <loss>=1.0194612797703648\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.775761929875968\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808658.4438539, \"EndTime\": 1715808658.7482638, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 303.74860763549805, \"count\": 1, \"min\": 303.74860763549805, \"max\": 303.74860763549805}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #progress_metric: host=algo-1, completed 45.05494505494506 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808658.4444902, \"EndTime\": 1715808658.7485158, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 40, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2894979.0, \"count\": 1, \"min\": 2894979, \"max\": 2894979}, \"Total Batches Seen\": {\"sum\": 2953.0, \"count\": 1, \"min\": 2953, \"max\": 2953}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 42.0, \"count\": 1, \"min\": 42, \"max\": 42}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=232079.09593748825 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=0.9219613522821976\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=0.8500127351020184\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:58 INFO 140500196235072] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.7253031740246164\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:59.033] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 283, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=1.0077643766397704\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=41, train mse <loss>=1.0155890388241449\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.7738766106294888\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808658.7483585, \"EndTime\": 1715808659.034358, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 285.40778160095215, \"count\": 1, \"min\": 285.40778160095215, \"max\": 285.40778160095215}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #progress_metric: host=algo-1, completed 46.15384615384615 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808658.7489233, \"EndTime\": 1715808659.034575, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 41, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2965564.0, \"count\": 1, \"min\": 2965564, \"max\": 2965564}, \"Total Batches Seen\": {\"sum\": 3025.0, \"count\": 1, \"min\": 3025, \"max\": 3025}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=247000.8300023611 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.9200306981264273\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=0.8464564854950013\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.7233960403043259\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:59.329] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 293, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=1.0058873700846138\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=42, train mse <loss>=1.011809401295741\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.7720358635578117\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808659.0344212, \"EndTime\": 1715808659.3303292, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 295.47905921936035, \"count\": 1, \"min\": 295.47905921936035, \"max\": 295.47905921936035}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #progress_metric: host=algo-1, completed 47.252747252747255 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808659.034823, \"EndTime\": 1715808659.3305678, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 42, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3036149.0, \"count\": 1, \"min\": 3036149, \"max\": 3036149}, \"Total Batches Seen\": {\"sum\": 3097.0, \"count\": 1, \"min\": 3097, \"max\": 3097}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 44.0, \"count\": 1, \"min\": 44, \"max\": 44}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=238571.02161165106 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.9181434017413543\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=0.8429873061611859\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.7215306610168826\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:59.634] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 301, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=1.0040517280821784\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=43, train mse <loss>=1.0081198726648084\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.7702385484306119\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808659.3304029, \"EndTime\": 1715808659.635776, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 304.917573928833, \"count\": 1, \"min\": 304.917573928833, \"max\": 304.917573928833}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #progress_metric: host=algo-1, completed 48.35164835164835 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808659.3308282, \"EndTime\": 1715808659.6362977, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 43, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3106734.0, \"count\": 1, \"min\": 3106734, \"max\": 3106734}, \"Total Batches Seen\": {\"sum\": 3169.0, \"count\": 1, \"min\": 3169, \"max\": 3169}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 45.0, \"count\": 1, \"min\": 45, \"max\": 45}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=230941.82425780804 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.9162983907862458\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=0.8396027409574636\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.7196975800113179\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:30:59.953] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 313, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=1.0022564738776256\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=44, train mse <loss>=1.0045180394296116\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.7684810339085293\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808659.63588, \"EndTime\": 1715808659.9537423, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 316.8377876281738, \"count\": 1, \"min\": 316.8377876281738, \"max\": 316.8377876281738}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #progress_metric: host=algo-1, completed 49.45054945054945 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808659.636876, \"EndTime\": 1715808659.9539702, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 44, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3177319.0, \"count\": 1, \"min\": 3177319, \"max\": 3177319}, \"Total Batches Seen\": {\"sum\": 3241.0, \"count\": 1, \"min\": 3241, \"max\": 3241}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 46.0, \"count\": 1, \"min\": 46, \"max\": 46}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=222509.03612846008 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.9144946454451666\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=0.836300456547881\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:30:59 INFO 140500196235072] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.7178969200947874\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:00.240] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 284, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=1.000500601686634\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=45, train mse <loss>=1.0010014539753167\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.7667666076414542\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808659.953814, \"EndTime\": 1715808660.2413015, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.8843078613281, \"count\": 1, \"min\": 286.8843078613281, \"max\": 286.8843078613281}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #progress_metric: host=algo-1, completed 50.54945054945055 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808659.9543903, \"EndTime\": 1715808660.2415338, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 45, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3247904.0, \"count\": 1, \"min\": 3247904, \"max\": 3247904}, \"Total Batches Seen\": {\"sum\": 3313.0, \"count\": 1, \"min\": 3313, \"max\": 3313}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 47.0, \"count\": 1, \"min\": 47, \"max\": 47}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=245715.6699655066 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.9127308294148312\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=0.8330775669642857\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.7161548391913984\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:00.548] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 304, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=0.9987830930594666\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=46, train mse <loss>=0.9975676669814351\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.7650959808874951\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808660.2413783, \"EndTime\": 1715808660.5492241, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 307.2652816772461, \"count\": 1, \"min\": 307.2652816772461, \"max\": 307.2652816772461}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #progress_metric: host=algo-1, completed 51.64835164835165 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808660.241935, \"EndTime\": 1715808660.5494173, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 46, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3318489.0, \"count\": 1, \"min\": 3318489, \"max\": 3318489}, \"Total Batches Seen\": {\"sum\": 3385.0, \"count\": 1, \"min\": 3385, \"max\": 3385}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=229477.18973621223 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.9110062309921384\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=0.8299323529065015\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.714450705699038\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:00.848] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 296, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=0.9971030262178664\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=47, train mse <loss>=0.9942144448928271\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.7634683656340714\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808660.549289, \"EndTime\": 1715808660.8490875, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 299.2243766784668, \"count\": 1, \"min\": 299.2243766784668, \"max\": 299.2243766784668}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #progress_metric: host=algo-1, completed 52.747252747252745 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808660.5498369, \"EndTime\": 1715808660.849309, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 47, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3389074.0, \"count\": 1, \"min\": 3389074, \"max\": 3389074}, \"Total Batches Seen\": {\"sum\": 3457.0, \"count\": 1, \"min\": 3457, \"max\": 3457}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 49.0, \"count\": 1, \"min\": 49, \"max\": 49}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=235609.74020888977 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.9093196552501569\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=0.8268622354242643\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:00 INFO 140500196235072] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.7127667125801685\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:01.131] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 279, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.9954594761477839\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.9909395686524202\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.7618799079538537\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808660.8491569, \"EndTime\": 1715808661.1318002, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.1969985961914, \"count\": 1, \"min\": 282.1969985961914, \"max\": 282.1969985961914}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #progress_metric: host=algo-1, completed 53.84615384615385 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808660.849578, \"EndTime\": 1715808661.1319554, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 48, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3459659.0, \"count\": 1, \"min\": 3459659, \"max\": 3459659}, \"Total Batches Seen\": {\"sum\": 3529.0, \"count\": 1, \"min\": 3529, \"max\": 3529}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 50.0, \"count\": 1, \"min\": 50, \"max\": 50}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=249877.57245104658 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.9076700287999053\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=0.8238648811816209\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.7111002808845259\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:01.426] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 292, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.9938513591703932\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.987740524124838\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.7603255556969203\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808661.1318603, \"EndTime\": 1715808661.42718, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 294.96264457702637, \"count\": 1, \"min\": 294.96264457702637, \"max\": 294.96264457702637}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #progress_metric: host=algo-1, completed 54.94505494505494 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808661.1321936, \"EndTime\": 1715808661.427426, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 49, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3530244.0, \"count\": 1, \"min\": 3530244, \"max\": 3530244}, \"Total Batches Seen\": {\"sum\": 3601.0, \"count\": 1, \"min\": 3601, \"max\": 3601}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 51.0, \"count\": 1, \"min\": 51, \"max\": 51}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=238987.96712265073 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=50, batch=0 train rmse <loss>=0.9060566046767693\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=50, batch=0 train mse <loss>=0.8209385708783954\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=50, batch=0 train absolute_loss <loss>=0.709466822910117\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:01.799] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 102, \"duration\": 370, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=50, train rmse <loss>=0.9922778712064845\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=50, train mse <loss>=0.9846153736860725\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=50, train absolute_loss <loss>=0.7588042053045269\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808661.427243, \"EndTime\": 1715808661.8006058, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 372.86853790283203, \"count\": 1, \"min\": 372.86853790283203, \"max\": 372.86853790283203}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #progress_metric: host=algo-1, completed 56.043956043956044 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808661.4276702, \"EndTime\": 1715808661.8009417, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 50, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3600829.0, \"count\": 1, \"min\": 3600829, \"max\": 3600829}, \"Total Batches Seen\": {\"sum\": 3673.0, \"count\": 1, \"min\": 3673, \"max\": 3673}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 52.0, \"count\": 1, \"min\": 52, \"max\": 52}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=189031.17020502244 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=51, batch=0 train rmse <loss>=0.904478117015965\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=51, batch=0 train mse <loss>=0.8180806641607458\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:01 INFO 140500196235072] #quality_metric: host=algo-1, epoch=51, batch=0 train absolute_loss <loss>=0.7078842070980571\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:02.182] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 104, \"duration\": 379, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=51, train rmse <loss>=0.9907380805902913\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=51, train mse <loss>=0.9815619443317347\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=51, train absolute_loss <loss>=0.7573165535367151\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808661.8006852, \"EndTime\": 1715808662.1834452, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 382.11846351623535, \"count\": 1, \"min\": 382.11846351623535, \"max\": 382.11846351623535}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #progress_metric: host=algo-1, completed 57.142857142857146 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808661.8013003, \"EndTime\": 1715808662.1836343, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 51, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3671414.0, \"count\": 1, \"min\": 3671414, \"max\": 3671414}, \"Total Batches Seen\": {\"sum\": 3745.0, \"count\": 1, \"min\": 3745, \"max\": 3745}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 53.0, \"count\": 1, \"min\": 53, \"max\": 53}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=184558.87260445277 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=52, batch=0 train rmse <loss>=0.9029337289753554\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=52, batch=0 train mse <loss>=0.8152893189213405\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=52, batch=0 train absolute_loss <loss>=0.7063322930748553\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:02.570] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 106, \"duration\": 383, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=52, train rmse <loss>=0.9892310334156583\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=52, train mse <loss>=0.9785780374726113\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=52, train absolute_loss <loss>=0.7558632988591816\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808662.1835146, \"EndTime\": 1715808662.5711262, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 387.2561454772949, \"count\": 1, \"min\": 387.2561454772949, \"max\": 387.2561454772949}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #progress_metric: host=algo-1, completed 58.24175824175824 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808662.1838427, \"EndTime\": 1715808662.5713282, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 52, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3741999.0, \"count\": 1, \"min\": 3741999, \"max\": 3741999}, \"Total Batches Seen\": {\"sum\": 3817.0, \"count\": 1, \"min\": 3817, \"max\": 3817}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=182103.94842493942 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=53, batch=0 train rmse <loss>=0.9014225940439081\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=53, batch=0 train mse <loss>=0.8125626930528483\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=53, batch=0 train absolute_loss <loss>=0.7048219492737676\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:02.918] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 108, \"duration\": 343, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=53, train rmse <loss>=0.98775587801287\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=53, train mse <loss>=0.9756616745489757\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=53, train absolute_loss <loss>=0.7544428302808387\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808662.5711985, \"EndTime\": 1715808662.9187787, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 347.19061851501465, \"count\": 1, \"min\": 347.19061851501465, \"max\": 347.19061851501465}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #progress_metric: host=algo-1, completed 59.34065934065934 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808662.5715654, \"EndTime\": 1715808662.9189255, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 53, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3812584.0, \"count\": 1, \"min\": 3812584, \"max\": 3812584}, \"Total Batches Seen\": {\"sum\": 3889.0, \"count\": 1, \"min\": 3889, \"max\": 3889}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 55.0, \"count\": 1, \"min\": 55, \"max\": 55}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=203143.71592056085 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=54, batch=0 train rmse <loss>=0.8999436174688354\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=54, batch=0 train mse <loss>=0.8098985146228936\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:02 INFO 140500196235072] #quality_metric: host=algo-1, epoch=54, batch=0 train absolute_loss <loss>=0.7033582107881665\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:03.359] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 110, \"duration\": 435, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=54, train rmse <loss>=0.9863116740539942\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=54, train mse <loss>=0.9728107183751925\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=54, train absolute_loss <loss>=0.7530549345948193\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808662.9188335, \"EndTime\": 1715808663.3602355, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 441.05982780456543, \"count\": 1, \"min\": 441.05982780456543, \"max\": 441.05982780456543}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #progress_metric: host=algo-1, completed 60.43956043956044 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808662.919127, \"EndTime\": 1715808663.3607492, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 54, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3883169.0, \"count\": 1, \"min\": 3883169, \"max\": 3883169}, \"Total Batches Seen\": {\"sum\": 3961.0, \"count\": 1, \"min\": 3961, \"max\": 3961}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 56.0, \"count\": 1, \"min\": 56, \"max\": 56}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=159781.6513175222 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=55, batch=0 train rmse <loss>=0.8984961379692242\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=55, batch=0 train mse <loss>=0.8072953099456112\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=55, batch=0 train absolute_loss <loss>=0.701944761832715\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:03.789] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 112, \"duration\": 425, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=55, train rmse <loss>=0.9848976783700294\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=55, train mse <loss>=0.9700234368586738\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=55, train absolute_loss <loss>=0.7516997832194448\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808663.3603241, \"EndTime\": 1715808663.790202, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 429.02493476867676, \"count\": 1, \"min\": 429.02493476867676, \"max\": 429.02493476867676}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #progress_metric: host=algo-1, completed 61.53846153846154 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808663.3611495, \"EndTime\": 1715808663.7904408, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 55, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3953754.0, \"count\": 1, \"min\": 3953754, \"max\": 3953754}, \"Total Batches Seen\": {\"sum\": 4033.0, \"count\": 1, \"min\": 4033, \"max\": 4033}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 57.0, \"count\": 1, \"min\": 57, \"max\": 57}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=164371.9645910785 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=56, batch=0 train rmse <loss>=0.8970790417174094\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=56, batch=0 train mse <loss>=0.8047508070886255\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:03 INFO 140500196235072] #quality_metric: host=algo-1, epoch=56, batch=0 train absolute_loss <loss>=0.7005633041412538\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:04.147] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 114, \"duration\": 353, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=56, train rmse <loss>=0.9835130231931793\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=56, train mse <loss>=0.9672978667905873\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=56, train absolute_loss <loss>=0.7503731930359828\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808663.7902768, \"EndTime\": 1715808664.1485763, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 357.851505279541, \"count\": 1, \"min\": 357.851505279541, \"max\": 357.851505279541}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #progress_metric: host=algo-1, completed 62.637362637362635 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808663.7906976, \"EndTime\": 1715808664.14881, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 56, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4024339.0, \"count\": 1, \"min\": 4024339, \"max\": 4024339}, \"Total Batches Seen\": {\"sum\": 4105.0, \"count\": 1, \"min\": 4105, \"max\": 4105}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 58.0, \"count\": 1, \"min\": 58, \"max\": 58}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=197032.38307699474 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=57, batch=0 train rmse <loss>=0.8956915817171198\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=57, batch=0 train mse <loss>=0.802263409558916\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=57, batch=0 train absolute_loss <loss>=0.6992379079162475\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:04.550] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 116, \"duration\": 398, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=57, train rmse <loss>=0.9821568231942746\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=57, train mse <loss>=0.9646320253470694\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=57, train absolute_loss <loss>=0.7490748774944044\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808664.1486502, \"EndTime\": 1715808664.5508838, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 401.8065929412842, \"count\": 1, \"min\": 401.8065929412842, \"max\": 401.8065929412842}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #progress_metric: host=algo-1, completed 63.73626373626374 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808664.1490498, \"EndTime\": 1715808664.5511472, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 57, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4094924.0, \"count\": 1, \"min\": 4094924, \"max\": 4094924}, \"Total Batches Seen\": {\"sum\": 4177.0, \"count\": 1, \"min\": 4177, \"max\": 4177}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 59.0, \"count\": 1, \"min\": 59, \"max\": 59}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=175479.0684265057 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=58, batch=0 train rmse <loss>=0.8943329690109184\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=58, batch=0 train mse <loss>=0.7998314594598843\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=58, batch=0 train absolute_loss <loss>=0.6979492310307155\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:04.927] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 118, \"duration\": 373, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=58, train rmse <loss>=0.980828357344498\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=58, train mse <loss>=0.9620242665711063\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=58, train absolute_loss <loss>=0.7478041748005939\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808664.5509717, \"EndTime\": 1715808664.927981, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 376.4612674713135, \"count\": 1, \"min\": 376.4612674713135, \"max\": 376.4612674713135}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #progress_metric: host=algo-1, completed 64.83516483516483 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808664.551476, \"EndTime\": 1715808664.9281898, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 58, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4165509.0, \"count\": 1, \"min\": 4165509, \"max\": 4165509}, \"Total Batches Seen\": {\"sum\": 4249.0, \"count\": 1, \"min\": 4249, \"max\": 4249}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 60.0, \"count\": 1, \"min\": 60, \"max\": 60}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=187305.65763084605 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=59, batch=0 train rmse <loss>=0.8930022694711482\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=59, batch=0 train mse <loss>=0.7974530532806212\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:04 INFO 140500196235072] #quality_metric: host=algo-1, epoch=59, batch=0 train absolute_loss <loss>=0.6966827822403169\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2024-05-15 21:31:05.210] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 120, \"duration\": 279, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=59, train rmse <loss>=0.9795268099351381\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=59, train mse <loss>=0.9594727713817082\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=59, train absolute_loss <loss>=0.7465603438474816\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808664.9280512, \"EndTime\": 1715808665.2108254, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 282.35435485839844, \"count\": 1, \"min\": 282.35435485839844, \"max\": 282.35435485839844}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #progress_metric: host=algo-1, completed 65.93406593406593 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808664.9284475, \"EndTime\": 1715808665.2110164, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 59, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4236094.0, \"count\": 1, \"min\": 4236094, \"max\": 4236094}, \"Total Batches Seen\": {\"sum\": 4321.0, \"count\": 1, \"min\": 4321, \"max\": 4321}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 61.0, \"count\": 1, \"min\": 61, \"max\": 61}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=249696.32764873572 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=60, batch=0 train rmse <loss>=0.8916988161587068\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=60, batch=0 train mse <loss>=0.7951267787388393\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=60, batch=0 train absolute_loss <loss>=0.695444947517134\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:05.497] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 122, \"duration\": 284, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=60, train rmse <loss>=0.9782514475709652\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=60, train mse <loss>=0.9569758946746888\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=60, train absolute_loss <loss>=0.7453422537858444\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808665.2108924, \"EndTime\": 1715808665.498078, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.8173122406006, \"count\": 1, \"min\": 286.8173122406006, \"max\": 286.8173122406006}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #progress_metric: host=algo-1, completed 67.03296703296704 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808665.211237, \"EndTime\": 1715808665.4982383, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 60, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4306679.0, \"count\": 1, \"min\": 4306679, \"max\": 4306679}, \"Total Batches Seen\": {\"sum\": 4393.0, \"count\": 1, \"min\": 4393, \"max\": 4393}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 62.0, \"count\": 1, \"min\": 62, \"max\": 62}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=245864.22495723088 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=61, batch=0 train rmse <loss>=0.8904218322466706\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=61, batch=0 train mse <loss>=0.7928510393415179\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=61, batch=0 train absolute_loss <loss>=0.6942276215889085\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:05.797] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 124, \"duration\": 297, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=61, train rmse <loss>=0.9770015300091431\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=61, train mse <loss>=0.9545319896402067\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=61, train absolute_loss <loss>=0.7441487004232972\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808665.4981399, \"EndTime\": 1715808665.7980468, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 299.61323738098145, \"count\": 1, \"min\": 299.61323738098145, \"max\": 299.61323738098145}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #progress_metric: host=algo-1, completed 68.13186813186813 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808665.4984086, \"EndTime\": 1715808665.7982674, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 61, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4377264.0, \"count\": 1, \"min\": 4377264, \"max\": 4377264}, \"Total Batches Seen\": {\"sum\": 4465.0, \"count\": 1, \"min\": 4465, \"max\": 4465}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 63.0, \"count\": 1, \"min\": 63, \"max\": 63}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=235305.62422307918 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=62, batch=0 train rmse <loss>=0.8891704649775998\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=62, batch=0 train mse <loss>=0.7906241157884809\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:05 INFO 140500196235072] #quality_metric: host=algo-1, epoch=62, batch=0 train absolute_loss <loss>=0.6930326465629716\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:06.100] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 126, \"duration\": 300, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=62, train rmse <loss>=0.975776249130363\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=62, train mse <loss>=0.9521392883669203\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=62, train absolute_loss <loss>=0.7429800223323447\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808665.7981231, \"EndTime\": 1715808666.101165, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 302.6266098022461, \"count\": 1, \"min\": 302.6266098022461, \"max\": 302.6266098022461}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #progress_metric: host=algo-1, completed 69.23076923076923 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808665.7985122, \"EndTime\": 1715808666.1013625, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 62, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4447849.0, \"count\": 1, \"min\": 4447849, \"max\": 4447849}, \"Total Batches Seen\": {\"sum\": 4537.0, \"count\": 1, \"min\": 4537, \"max\": 4537}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 64.0, \"count\": 1, \"min\": 64, \"max\": 64}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=232986.44824568584 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=63, batch=0 train rmse <loss>=0.8879441311299794\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=63, batch=0 train mse <loss>=0.7884447800081741\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=63, batch=0 train absolute_loss <loss>=0.6918587943677691\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:06.380] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 128, \"duration\": 277, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=63, train rmse <loss>=0.9745750161735288\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=63, train mse <loss>=0.9497964621496339\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=63, train absolute_loss <loss>=0.7418348285513865\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808666.1012297, \"EndTime\": 1715808666.3808372, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.23059463500977, \"count\": 1, \"min\": 279.23059463500977, \"max\": 279.23059463500977}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #progress_metric: host=algo-1, completed 70.32967032967034 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808666.1015785, \"EndTime\": 1715808666.381069, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 63, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4518434.0, \"count\": 1, \"min\": 4518434, \"max\": 4518434}, \"Total Batches Seen\": {\"sum\": 4609.0, \"count\": 1, \"min\": 4609, \"max\": 4609}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 65.0, \"count\": 1, \"min\": 65, \"max\": 65}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=252456.47242211757 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=64, batch=0 train rmse <loss>=0.886741999740623\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=64, batch=0 train mse <loss>=0.786311374103999\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=64, batch=0 train absolute_loss <loss>=0.690713433432627\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:06.676] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 130, \"duration\": 292, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=64, train rmse <loss>=0.9733971062392325\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=64, train mse <loss>=0.9475019264349116\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=64, train absolute_loss <loss>=0.7407128393530126\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808666.3809144, \"EndTime\": 1715808666.6766322, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 295.26805877685547, \"count\": 1, \"min\": 295.26805877685547, \"max\": 295.26805877685547}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #progress_metric: host=algo-1, completed 71.42857142857143 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808666.3813398, \"EndTime\": 1715808666.6767905, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 64, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4589019.0, \"count\": 1, \"min\": 4589019, \"max\": 4589019}, \"Total Batches Seen\": {\"sum\": 4681.0, \"count\": 1, \"min\": 4681, \"max\": 4681}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=238824.6745932062 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=65, batch=0 train rmse <loss>=0.8855634066498265\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=65, batch=0 train mse <loss>=0.7842225471972459\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=65, batch=0 train absolute_loss <loss>=0.6895988970934985\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:06.963] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 132, \"duration\": 285, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=65, train rmse <loss>=0.9722418602525644\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=65, train mse <loss>=0.945254234827367\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=65, train absolute_loss <loss>=0.7396128462807007\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808666.6766958, \"EndTime\": 1715808666.9644787, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 287.4884605407715, \"count\": 1, \"min\": 287.4884605407715, \"max\": 287.4884605407715}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #progress_metric: host=algo-1, completed 72.52747252747253 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808666.6769652, \"EndTime\": 1715808666.9646893, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 65, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4659604.0, \"count\": 1, \"min\": 4659604, \"max\": 4659604}, \"Total Batches Seen\": {\"sum\": 4753.0, \"count\": 1, \"min\": 4753, \"max\": 4753}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 67.0, \"count\": 1, \"min\": 67, \"max\": 67}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=245233.08793039323 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=66, batch=0 train rmse <loss>=0.8844076475277831\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=66, batch=0 train mse <loss>=0.7821768870056275\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:06 INFO 140500196235072] #quality_metric: host=algo-1, epoch=66, batch=0 train absolute_loss <loss>=0.688512483592964\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:07.251] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 134, \"duration\": 284, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=66, train rmse <loss>=0.9711085862820161\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=66, train mse <loss>=0.9430518863506561\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=66, train absolute_loss <loss>=0.7385351768201985\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808666.9645462, \"EndTime\": 1715808667.2523994, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 287.2352600097656, \"count\": 1, \"min\": 287.2352600097656, \"max\": 287.2352600097656}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #progress_metric: host=algo-1, completed 73.62637362637362 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808666.965142, \"EndTime\": 1715808667.2525616, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 66, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4730189.0, \"count\": 1, \"min\": 4730189, \"max\": 4730189}, \"Total Batches Seen\": {\"sum\": 4825.0, \"count\": 1, \"min\": 4825, \"max\": 4825}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 68.0, \"count\": 1, \"min\": 68, \"max\": 68}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=245502.33460898986 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=67, batch=0 train rmse <loss>=0.8832742558638852\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=67, batch=0 train mse <loss>=0.7801734110719002\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=67, batch=0 train absolute_loss <loss>=0.6874364472970637\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:07.561] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 136, \"duration\": 306, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=67, train rmse <loss>=0.9699967001759678\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=67, train mse <loss>=0.9408935983522664\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=67, train absolute_loss <loss>=0.7374775940050569\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808667.2524612, \"EndTime\": 1715808667.5617394, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 308.72178077697754, \"count\": 1, \"min\": 308.72178077697754, \"max\": 308.72178077697754}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #progress_metric: host=algo-1, completed 74.72527472527473 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808667.2529929, \"EndTime\": 1715808667.56197, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 67, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4800774.0, \"count\": 1, \"min\": 4800774, \"max\": 4800774}, \"Total Batches Seen\": {\"sum\": 4897.0, \"count\": 1, \"min\": 4897, \"max\": 4897}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 69.0, \"count\": 1, \"min\": 69, \"max\": 69}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=228363.80537758654 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=68, batch=0 train rmse <loss>=0.8821623781931904\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=68, batch=0 train mse <loss>=0.7782104614994655\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=68, batch=0 train absolute_loss <loss>=0.6863711566272636\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:07.841] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 138, \"duration\": 277, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=68, train rmse <loss>=0.9689056167395657\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=68, train mse <loss>=0.938778094149478\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=68, train absolute_loss <loss>=0.7364414580950874\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808667.5618114, \"EndTime\": 1715808667.8423684, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.8011302947998, \"count\": 1, \"min\": 279.8011302947998, \"max\": 279.8011302947998}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #progress_metric: host=algo-1, completed 75.82417582417582 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808667.5625415, \"EndTime\": 1715808667.842558, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 68, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4871359.0, \"count\": 1, \"min\": 4871359, \"max\": 4871359}, \"Total Batches Seen\": {\"sum\": 4969.0, \"count\": 1, \"min\": 4969, \"max\": 4969}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 70.0, \"count\": 1, \"min\": 70, \"max\": 70}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=251988.0360582427 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=69, batch=0 train rmse <loss>=0.8810715732757799\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=69, batch=0 train mse <loss>=0.7762871172346579\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:07 INFO 140500196235072] #quality_metric: host=algo-1, epoch=69, batch=0 train absolute_loss <loss>=0.6853218308876697\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:08.130] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 140, \"duration\": 285, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=69, train rmse <loss>=0.96783474589101\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=69, train mse <loss>=0.9367040953539161\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=69, train absolute_loss <loss>=0.7354285199450828\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808667.8424447, \"EndTime\": 1715808668.131431, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 288.318395614624, \"count\": 1, \"min\": 288.318395614624, \"max\": 288.318395614624}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #progress_metric: host=algo-1, completed 76.92307692307692 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808667.8430877, \"EndTime\": 1715808668.1317897, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 69, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4941944.0, \"count\": 1, \"min\": 4941944, \"max\": 4941944}, \"Total Batches Seen\": {\"sum\": 5041.0, \"count\": 1, \"min\": 5041, \"max\": 5041}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 71.0, \"count\": 1, \"min\": 71, \"max\": 71}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=244345.96585403697 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=70, batch=0 train rmse <loss>=0.8800012565954101\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=70, batch=0 train mse <loss>=0.7744022116095007\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=70, batch=0 train absolute_loss <loss>=0.684291110432124\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:08.416] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 142, \"duration\": 281, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=70, train rmse <loss>=0.9667834579150496\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=70, train mse <loss>=0.9346702544981805\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=70, train absolute_loss <loss>=0.7344346331078921\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808668.1315022, \"EndTime\": 1715808668.4165442, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.9329242706299, \"count\": 1, \"min\": 283.9329242706299, \"max\": 283.9329242706299}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #progress_metric: host=algo-1, completed 78.02197802197803 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808668.132587, \"EndTime\": 1715808668.4167511, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 70, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5012529.0, \"count\": 1, \"min\": 5012529, \"max\": 5012529}, \"Total Batches Seen\": {\"sum\": 5113.0, \"count\": 1, \"min\": 5113, \"max\": 5113}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=248311.58312868205 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=71, batch=0 train rmse <loss>=0.8789506646781313\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=71, batch=0 train mse <loss>=0.7725542709381288\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=71, batch=0 train absolute_loss <loss>=0.6832791794713594\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:08.726] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 144, \"duration\": 306, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=71, train rmse <loss>=0.96575126042872\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=71, train mse <loss>=0.9326754970196613\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=71, train absolute_loss <loss>=0.73345819597353\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808668.416604, \"EndTime\": 1715808668.727079, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 309.7507953643799, \"count\": 1, \"min\": 309.7507953643799, \"max\": 309.7507953643799}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #progress_metric: host=algo-1, completed 79.12087912087912 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808668.417299, \"EndTime\": 1715808668.7273867, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 71, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5083114.0, \"count\": 1, \"min\": 5083114, \"max\": 5083114}, \"Total Batches Seen\": {\"sum\": 5185.0, \"count\": 1, \"min\": 5185, \"max\": 5185}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 73.0, \"count\": 1, \"min\": 73, \"max\": 73}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=227528.39952719767 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=72, batch=0 train rmse <loss>=0.8779194137129169\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=72, batch=0 train mse <loss>=0.7707424969740317\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:08 INFO 140500196235072] #quality_metric: host=algo-1, epoch=72, batch=0 train absolute_loss <loss>=0.6822839502837337\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:09.015] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 146, \"duration\": 285, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=72, train rmse <loss>=0.9647375707148226\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=72, train mse <loss>=0.9307185803487373\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=72, train absolute_loss <loss>=0.7325000588109822\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808668.7271805, \"EndTime\": 1715808669.0157356, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 287.69588470458984, \"count\": 1, \"min\": 287.69588470458984, \"max\": 287.69588470458984}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #progress_metric: host=algo-1, completed 80.21978021978022 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808668.7280157, \"EndTime\": 1715808669.0158966, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 72, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5153699.0, \"count\": 1, \"min\": 5153699, \"max\": 5153699}, \"Total Batches Seen\": {\"sum\": 5257.0, \"count\": 1, \"min\": 5257, \"max\": 5257}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 74.0, \"count\": 1, \"min\": 74, \"max\": 74}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=245107.2085731861 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=73, batch=0 train rmse <loss>=0.876906976740628\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=73, batch=0 train mse <loss>=0.7689658458563883\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=73, batch=0 train absolute_loss <loss>=0.6813035807619152\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:09.305] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 148, \"duration\": 286, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=73, train rmse <loss>=0.9637419095899247\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=73, train mse <loss>=0.9287984683000345\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=73, train absolute_loss <loss>=0.7315592280762483\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808669.0157988, \"EndTime\": 1715808669.3062181, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 289.69788551330566, \"count\": 1, \"min\": 289.69788551330566, \"max\": 289.69788551330566}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #progress_metric: host=algo-1, completed 81.31868131868131 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808669.016482, \"EndTime\": 1715808669.3065019, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 73, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5224284.0, \"count\": 1, \"min\": 5224284, \"max\": 5224284}, \"Total Batches Seen\": {\"sum\": 5329.0, \"count\": 1, \"min\": 5329, \"max\": 5329}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=243290.7745318549 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=74, batch=0 train rmse <loss>=0.8759126478744835\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=74, batch=0 train mse <loss>=0.7672229667064889\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=74, batch=0 train absolute_loss <loss>=0.6803386849416814\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:09.610] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 150, \"duration\": 301, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=74, train rmse <loss>=0.9627638001722482\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=74, train mse <loss>=0.9269141349221086\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=74, train absolute_loss <loss>=0.7306353396119992\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808669.306286, \"EndTime\": 1715808669.6107461, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 303.75146865844727, \"count\": 1, \"min\": 303.75146865844727, \"max\": 303.75146865844727}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #progress_metric: host=algo-1, completed 82.41758241758242 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808669.3069713, \"EndTime\": 1715808669.6109471, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 74, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5294869.0, \"count\": 1, \"min\": 5294869, \"max\": 5294869}, \"Total Batches Seen\": {\"sum\": 5401.0, \"count\": 1, \"min\": 5401, \"max\": 5401}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 76.0, \"count\": 1, \"min\": 76, \"max\": 76}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=232117.48911171168 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=75, batch=0 train rmse <loss>=0.8749361379486827\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=75, batch=0 train mse <loss>=0.7655132454885564\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=75, batch=0 train absolute_loss <loss>=0.6793938066877829\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:09.913] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 152, \"duration\": 299, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=75, train rmse <loss>=0.9618026398540952\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=75, train mse <loss>=0.9250643180303064\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=75, train absolute_loss <loss>=0.7297279891780152\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808669.610811, \"EndTime\": 1715808669.9137323, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 302.20913887023926, \"count\": 1, \"min\": 302.20913887023926, \"max\": 302.20913887023926}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #progress_metric: host=algo-1, completed 83.51648351648352 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808669.6115, \"EndTime\": 1715808669.913891, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 75, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5365454.0, \"count\": 1, \"min\": 5365454, \"max\": 5365454}, \"Total Batches Seen\": {\"sum\": 5473.0, \"count\": 1, \"min\": 5473, \"max\": 5473}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 77.0, \"count\": 1, \"min\": 77, \"max\": 77}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=233348.21532781704 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=76, batch=0 train rmse <loss>=0.8739768392438176\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=76, batch=0 train mse <loss>=0.7638355155346139\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:09 INFO 140500196235072] #quality_metric: host=algo-1, epoch=76, batch=0 train absolute_loss <loss>=0.6784598582707181\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:10.214] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 154, \"duration\": 298, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=76, train rmse <loss>=0.960858118702182\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=76, train mse <loss>=0.9232483242758963\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=76, train absolute_loss <loss>=0.7288372791135922\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808669.913793, \"EndTime\": 1715808670.215246, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 300.8131980895996, \"count\": 1, \"min\": 300.8131980895996, \"max\": 300.8131980895996}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #progress_metric: host=algo-1, completed 84.61538461538461 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808669.914407, \"EndTime\": 1715808670.2154713, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 76, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5436039.0, \"count\": 1, \"min\": 5436039, \"max\": 5436039}, \"Total Batches Seen\": {\"sum\": 5545.0, \"count\": 1, \"min\": 5545, \"max\": 5545}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 78.0, \"count\": 1, \"min\": 78, \"max\": 78}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=234361.4146785926 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=77, batch=0 train rmse <loss>=0.8730344216612005\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=77, batch=0 train mse <loss>=0.7621891014053068\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=77, batch=0 train absolute_loss <loss>=0.6775346291616888\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:10.513] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 156, \"duration\": 295, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=77, train rmse <loss>=0.9599297008037112\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=77, train mse <loss>=0.9214650304851024\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=77, train absolute_loss <loss>=0.7279626670204604\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808670.2153203, \"EndTime\": 1715808670.5140698, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 298.0172634124756, \"count\": 1, \"min\": 298.0172634124756, \"max\": 298.0172634124756}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #progress_metric: host=algo-1, completed 85.71428571428571 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808670.216026, \"EndTime\": 1715808670.514277, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 77, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5506624.0, \"count\": 1, \"min\": 5506624, \"max\": 5506624}, \"Total Batches Seen\": {\"sum\": 5617.0, \"count\": 1, \"min\": 5617, \"max\": 5617}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 79.0, \"count\": 1, \"min\": 79, \"max\": 79}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=236594.87119160948 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=78, batch=0 train rmse <loss>=0.8721082358452308\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=78, batch=0 train mse <loss>=0.7605727750290807\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=78, batch=0 train absolute_loss <loss>=0.6766277597223969\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:10.799] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 158, \"duration\": 282, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=78, train rmse <loss>=0.9590169082563208\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=78, train mse <loss>=0.9197134303215124\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=78, train absolute_loss <loss>=0.7271050986842823\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808670.5141456, \"EndTime\": 1715808670.7994952, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 284.665584564209, \"count\": 1, \"min\": 284.665584564209, \"max\": 284.665584564209}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #progress_metric: host=algo-1, completed 86.81318681318682 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808670.5148056, \"EndTime\": 1715808670.799662, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 78, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5577209.0, \"count\": 1, \"min\": 5577209, \"max\": 5577209}, \"Total Batches Seen\": {\"sum\": 5689.0, \"count\": 1, \"min\": 5689, \"max\": 5689}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 80.0, \"count\": 1, \"min\": 80, \"max\": 80}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=247700.16092502186 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=79, batch=0 train rmse <loss>=0.8711979811559245\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=79, batch=0 train mse <loss>=0.7589859223701585\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:10 INFO 140500196235072] #quality_metric: host=algo-1, epoch=79, batch=0 train absolute_loss <loss>=0.6757339078415807\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:11.089] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 160, \"duration\": 287, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=79, train rmse <loss>=0.9581194319015186\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=79, train mse <loss>=0.9179928457872888\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=79, train absolute_loss <loss>=0.726263831292333\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808670.7995622, \"EndTime\": 1715808671.0901117, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 289.9284362792969, \"count\": 1, \"min\": 289.9284362792969, \"max\": 289.9284362792969}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #progress_metric: host=algo-1, completed 87.91208791208791 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808670.800157, \"EndTime\": 1715808671.0903413, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 79, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5647794.0, \"count\": 1, \"min\": 5647794, \"max\": 5647794}, \"Total Batches Seen\": {\"sum\": 5761.0, \"count\": 1, \"min\": 5761, \"max\": 5761}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=243140.31999868597 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=80, batch=0 train rmse <loss>=0.8703030725926119\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=80, batch=0 train mse <loss>=0.757427438164141\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=80, batch=0 train absolute_loss <loss>=0.6748586612448126\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:11.382] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 162, \"duration\": 289, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=80, train rmse <loss>=0.9572367936275192\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=80, train mse <loss>=0.9163022790742938\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=80, train absolute_loss <loss>=0.7254384375780508\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808671.0901837, \"EndTime\": 1715808671.382991, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 292.36650466918945, \"count\": 1, \"min\": 292.36650466918945, \"max\": 292.36650466918945}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #progress_metric: host=algo-1, completed 89.01098901098901 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808671.0905962, \"EndTime\": 1715808671.3832188, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 80, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5718379.0, \"count\": 1, \"min\": 5718379, \"max\": 5718379}, \"Total Batches Seen\": {\"sum\": 5833.0, \"count\": 1, \"min\": 5833, \"max\": 5833}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 82.0, \"count\": 1, \"min\": 82, \"max\": 82}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=241110.06328778883 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=81, batch=0 train rmse <loss>=0.8694232397278263\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=81, batch=0 train mse <loss>=0.7558967697788292\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=81, batch=0 train absolute_loss <loss>=0.673991519920303\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:11.669] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 164, \"duration\": 284, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=81, train rmse <loss>=0.956368594445581\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=81, train mse <loss>=0.9146408884418162\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=81, train absolute_loss <loss>=0.7246270182946638\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808671.3830662, \"EndTime\": 1715808671.6702466, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.4692211151123, \"count\": 1, \"min\": 286.4692211151123, \"max\": 286.4692211151123}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #progress_metric: host=algo-1, completed 90.10989010989012 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808671.3837545, \"EndTime\": 1715808671.6704044, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 81, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5788964.0, \"count\": 1, \"min\": 5788964, \"max\": 5788964}, \"Total Batches Seen\": {\"sum\": 5905.0, \"count\": 1, \"min\": 5905, \"max\": 5905}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 83.0, \"count\": 1, \"min\": 83, \"max\": 83}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=246159.0090280353 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=82, batch=0 train rmse <loss>=0.8685580335038844\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=82, batch=0 train mse <loss>=0.7543930575641348\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=82, batch=0 train absolute_loss <loss>=0.6731355540469379\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:11.956] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 166, \"duration\": 283, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=82, train rmse <loss>=0.9555144180769911\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=82, train mse <loss>=0.913007803153011\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=82, train absolute_loss <loss>=0.7238300390859698\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808671.6703084, \"EndTime\": 1715808671.9571364, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 286.53621673583984, \"count\": 1, \"min\": 286.53621673583984, \"max\": 286.53621673583984}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #progress_metric: host=algo-1, completed 91.20879120879121 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808671.670577, \"EndTime\": 1715808671.9572961, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 82, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5859549.0, \"count\": 1, \"min\": 5859549, \"max\": 5859549}, \"Total Batches Seen\": {\"sum\": 5977.0, \"count\": 1, \"min\": 5977, \"max\": 5977}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 84.0, \"count\": 1, \"min\": 84, \"max\": 84}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=246105.19197214209 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=83, batch=0 train rmse <loss>=0.8677071792303314\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=83, batch=0 train mse <loss>=0.7529157488878584\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:11 INFO 140500196235072] #quality_metric: host=algo-1, epoch=83, batch=0 train absolute_loss <loss>=0.6722992373184419\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:12.237] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 168, \"duration\": 277, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=83, train rmse <loss>=0.954674018533256\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=83, train mse <loss>=0.9114024816624355\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=83, train absolute_loss <loss>=0.7230482436175211\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808671.9571989, \"EndTime\": 1715808672.2375238, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 280.0323963165283, \"count\": 1, \"min\": 280.0323963165283, \"max\": 280.0323963165283}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #progress_metric: host=algo-1, completed 92.3076923076923 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808671.957469, \"EndTime\": 1715808672.237698, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 83, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5930134.0, \"count\": 1, \"min\": 5930134, \"max\": 5930134}, \"Total Batches Seen\": {\"sum\": 6049.0, \"count\": 1, \"min\": 6049, \"max\": 6049}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 85.0, \"count\": 1, \"min\": 85, \"max\": 85}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=251803.93203916526 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=84, batch=0 train rmse <loss>=0.8668700816648369\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=84, batch=0 train mse <loss>=0.7514637384856011\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=84, batch=0 train absolute_loss <loss>=0.6714772890271316\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:12.517] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 170, \"duration\": 277, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=84, train rmse <loss>=0.9538469243846657\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=84, train mse <loss>=0.9098239551580861\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=84, train absolute_loss <loss>=0.7222800055473356\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808672.2375982, \"EndTime\": 1715808672.5175424, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 279.649019241333, \"count\": 1, \"min\": 279.649019241333, \"max\": 279.649019241333}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #progress_metric: host=algo-1, completed 93.4065934065934 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808672.2378693, \"EndTime\": 1715808672.5177002, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 84, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6000719.0, \"count\": 1, \"min\": 6000719, \"max\": 6000719}, \"Total Batches Seen\": {\"sum\": 6121.0, \"count\": 1, \"min\": 6121, \"max\": 6121}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 86.0, \"count\": 1, \"min\": 86, \"max\": 86}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=252156.73047489504 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=85, batch=0 train rmse <loss>=0.8660464970939732\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=85, batch=0 train mse <loss>=0.7500365351287412\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=85, batch=0 train absolute_loss <loss>=0.6706688495229187\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:12.802] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 172, \"duration\": 283, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=85, train rmse <loss>=0.9530328320170279\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=85, train mse <loss>=0.9082715789023966\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=85, train absolute_loss <loss>=0.7215251679551593\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808672.5176032, \"EndTime\": 1715808672.8034708, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 285.5720520019531, \"count\": 1, \"min\": 285.5720520019531, \"max\": 285.5720520019531}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #progress_metric: host=algo-1, completed 94.50549450549451 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808672.5178726, \"EndTime\": 1715808672.8036857, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 85, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6071304.0, \"count\": 1, \"min\": 6071304, \"max\": 6071304}, \"Total Batches Seen\": {\"sum\": 6193.0, \"count\": 1, \"min\": 6193, \"max\": 6193}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 87.0, \"count\": 1, \"min\": 87, \"max\": 87}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=246868.80677762584 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=86, batch=0 train rmse <loss>=0.865236109268159\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=86, batch=0 train mse <loss>=0.7486335247815015\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:12 INFO 140500196235072] #quality_metric: host=algo-1, epoch=86, batch=0 train absolute_loss <loss>=0.6698693135374748\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:13.087] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 174, \"duration\": 280, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=86, train rmse <loss>=0.9522314366847108\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=86, train mse <loss>=0.9067447090106284\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=86, train absolute_loss <loss>=0.720782943681239\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808672.8035429, \"EndTime\": 1715808673.0876777, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.43892097473145, \"count\": 1, \"min\": 283.43892097473145, \"max\": 283.43892097473145}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #progress_metric: host=algo-1, completed 95.6043956043956 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808672.804215, \"EndTime\": 1715808673.0878334, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 86, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6141889.0, \"count\": 1, \"min\": 6141889, \"max\": 6141889}, \"Total Batches Seen\": {\"sum\": 6265.0, \"count\": 1, \"min\": 6265, \"max\": 6265}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 88.0, \"count\": 1, \"min\": 88, \"max\": 88}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=248791.73344560497 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=87, batch=0 train rmse <loss>=0.8644386001377454\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=87, batch=0 train mse <loss>=0.7472540934081049\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=87, batch=0 train absolute_loss <loss>=0.6690786810707998\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:13.370] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 176, \"duration\": 280, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=87, train rmse <loss>=0.9514423662168956\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=87, train mse <loss>=0.9052425762324052\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=87, train absolute_loss <loss>=0.7200529071646677\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808673.0877368, \"EndTime\": 1715808673.371688, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 283.2667827606201, \"count\": 1, \"min\": 283.2667827606201, \"max\": 283.2667827606201}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #progress_metric: host=algo-1, completed 96.7032967032967 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808673.0883818, \"EndTime\": 1715808673.3719954, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 87, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6212474.0, \"count\": 1, \"min\": 6212474, \"max\": 6212474}, \"Total Batches Seen\": {\"sum\": 6337.0, \"count\": 1, \"min\": 6337, \"max\": 6337}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 89.0, \"count\": 1, \"min\": 89, \"max\": 89}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=248763.72071371853 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=88, batch=0 train rmse <loss>=0.8636534721489202\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=88, batch=0 train mse <loss>=0.7458973199548856\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=88, batch=0 train absolute_loss <loss>=0.6683103995064135\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:13.687] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 178, \"duration\": 312, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=88, train rmse <loss>=0.9506653494341955\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=88, train mse <loss>=0.9037646066148409\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=88, train absolute_loss <loss>=0.7193353398385103\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808673.3717554, \"EndTime\": 1715808673.6879382, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 315.39082527160645, \"count\": 1, \"min\": 315.39082527160645, \"max\": 315.39082527160645}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #progress_metric: host=algo-1, completed 97.8021978021978 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808673.3725212, \"EndTime\": 1715808673.688167, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 88, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6283059.0, \"count\": 1, \"min\": 6283059, \"max\": 6283059}, \"Total Batches Seen\": {\"sum\": 6409.0, \"count\": 1, \"min\": 6409, \"max\": 6409}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 90.0, \"count\": 1, \"min\": 90, \"max\": 90}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=223538.5840854967 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=89, batch=0 train rmse <loss>=0.8628805811953094\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=89, batch=0 train mse <loss>=0.744562897403955\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:13 INFO 140500196235072] #quality_metric: host=algo-1, epoch=89, batch=0 train absolute_loss <loss>=0.6675507758464851\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:14.004] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 180, \"duration\": 314, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, epoch=89, train rmse <loss>=0.949900057691132\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, epoch=89, train mse <loss>=0.9023101196016158\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, epoch=89, train absolute_loss <loss>=0.7186308395348218\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808673.6880083, \"EndTime\": 1715808674.0053346, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 316.8659210205078, \"count\": 1, \"min\": 316.8659210205078, \"max\": 316.8659210205078}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #progress_metric: host=algo-1, completed 98.9010989010989 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808673.6884441, \"EndTime\": 1715808674.0054874, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 89, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6353644.0, \"count\": 1, \"min\": 6353644, \"max\": 6353644}, \"Total Batches Seen\": {\"sum\": 6481.0, \"count\": 1, \"min\": 6481, \"max\": 6481}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=222562.22905822532 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, epoch=90, batch=0 train rmse <loss>=0.862119604068679\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, epoch=90, batch=0 train mse <loss>=0.743250211719536\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, epoch=90, batch=0 train absolute_loss <loss>=0.6668028802699006\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:14.320] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 182, \"duration\": 313, \"num_examples\": 72, \"num_bytes\": 4517440}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, epoch=90, train rmse <loss>=0.9491462574304951\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, epoch=90, train mse <loss>=0.9008786179943157\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, epoch=90, train absolute_loss <loss>=0.7179379555940788\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, train rmse <loss>=0.9491462574304951\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, train mse <loss>=0.9008786179943157\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, train absolute_loss <loss>=0.7179379555940788\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808674.0053947, \"EndTime\": 1715808674.321633, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 315.9370422363281, \"count\": 1, \"min\": 315.9370422363281, \"max\": 315.9370422363281}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808674.0056586, \"EndTime\": 1715808674.3219209, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 90, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6424229.0, \"count\": 1, \"min\": 6424229, \"max\": 6424229}, \"Total Batches Seen\": {\"sum\": 6553.0, \"count\": 1, \"min\": 6553, \"max\": 6553}, \"Max Records Seen Between Resets\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Max Batches Seen Between Resets\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}, \"Reset Count\": {\"sum\": 92.0, \"count\": 1, \"min\": 92, \"max\": 92}, \"Number of Records Since Last Reset\": {\"sum\": 70585.0, \"count\": 1, \"min\": 70585, \"max\": 70585}, \"Number of Batches Since Last Reset\": {\"sum\": 72.0, \"count\": 1, \"min\": 72, \"max\": 72}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #throughput_metric: host=algo-1, train throughput=223098.08227023468 records/second\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 WARNING 140500196235072] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808674.3217177, \"EndTime\": 1715808674.326538, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 4.242658615112305, \"count\": 1, \"min\": 4.242658615112305, \"max\": 4.242658615112305}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] Saved checkpoint to \"/tmp/tmpzpid09fj/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:14.333] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 28016, \"num_examples\": 1, \"num_bytes\": 63616}\u001b[0m\n",
      "\u001b[34m[2024-05-15 21:31:14.414] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 80, \"num_examples\": 31, \"num_bytes\": 1936064}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808674.3334117, \"EndTime\": 1715808674.414604, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30251.0, \"count\": 1, \"min\": 30251, \"max\": 30251}, \"Total Batches Seen\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Max Records Seen Between Resets\": {\"sum\": 30251.0, \"count\": 1, \"min\": 30251, \"max\": 30251}, \"Max Batches Seen Between Resets\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 30251.0, \"count\": 1, \"min\": 30251, \"max\": 30251}, \"Number of Batches Since Last Reset\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}}}\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #test_score (algo-1) : ('rmse', 0.9069811409492536)\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #test_score (algo-1) : ('mse', 0.8226147900376098)\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #test_score (algo-1) : ('absolute_loss', 0.7209633612237896)\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, test rmse <loss>=0.9069811409492536\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, test mse <loss>=0.8226147900376098\u001b[0m\n",
      "\u001b[34m[05/15/2024 21:31:14 INFO 140500196235072] #quality_metric: host=algo-1, test absolute_loss <loss>=0.7209633612237896\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1715808674.326648, \"EndTime\": 1715808674.4152489, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 17.104625701904297, \"count\": 1, \"min\": 17.104625701904297, \"max\": 17.104625701904297}, \"totaltime\": {\"sum\": 28126.00064277649, \"count\": 1, \"min\": 28126.00064277649, \"max\": 28126.00064277649}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-05-15 21:31:34 Uploading - Uploading generated training model\n",
      "2024-05-15 21:31:34 Completed - Training job completed\n",
      "Training seconds: 274\n",
      "Billable seconds: 121\n",
      "Managed Spot Training savings: 55.8%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train':s3_training_file_location, 'test':s3_test_file_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db5e8e",
   "metadata": {},
   "source": [
    "### Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34a978b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: fm-movie-v4-2024-05-15-21-44-16-905\n",
      "INFO:sagemaker:Creating endpoint-config with name fm-movie-v4\n",
      "INFO:sagemaker:Creating endpoint with name fm-movie-v4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                            instance_type='ml.m5.xlarge',\n",
    "                             endpoint_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd76fb4",
   "metadata": {},
   "source": [
    "#### Run Predictions\n",
    "#### Dense and Sparse Formats\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4314725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fm_sparse_serializer(data):\n",
    "    js = {'instances':[]}\n",
    "    \n",
    "    for row in data:\n",
    "        \n",
    "        column_list = row.tolist()\n",
    "        value_list = np.ones(len(column_list),dtype=int).tolist()\n",
    "        \n",
    "        js['instances'].append({'data':{'features':{'keys':column_list, 'shape':[dim_movie], 'values': value_list}}})\n",
    "        \n",
    "    return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7275b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"instances\": [{\"data\": {\"features\": {\"keys\": [341, 1416], \"shape\": [10334], \"values\": [1, 1]}}}]}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_sparse_serializer([np.array([341,1416])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97e68588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDK 2\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "211a3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify custom serializer\n",
    "\n",
    "predictor.serializer.serialize = fm_sparse_serializer\n",
    "predictor.serializer.content_type='application/json'\n",
    "\n",
    "predictor.deserializer=JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecc59895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 2.8631527423858643}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict([np.array([341,1416])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa1aa95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ['2.5', '426:1', '943:1']\n",
      "    Actual Rating: \t2.5\n",
      "    Predicted Rating: \t2.8515758514404297\n",
      "Movie ['3', '110:1', '10120:1']\n",
      "    Actual Rating: \t3\n",
      "    Predicted Rating: \t3.107433795928955\n",
      "Movie ['4', '304:1', '1554:1']\n",
      "    Actual Rating: \t4\n",
      "    Predicted Rating: \t4.020742416381836\n",
      "Movie ['5', '273:1', '867:1']\n",
      "    Actual Rating: \t5\n",
      "    Predicted Rating: \t4.1318769454956055\n",
      "Movie ['2', '18:1', '3373:1']\n",
      "    Actual Rating: \t2\n",
      "    Predicted Rating: \t2.294043779373169\n"
     ]
    }
   ],
   "source": [
    "# Test with few entries from test file\n",
    "\n",
    "with open(r'ml-latest-small/user_movie_test.svm','r') as f:\n",
    "    \n",
    "    for i in range(5):\n",
    "        rating = f.readline().split()\n",
    "        print(f'Movie {rating}')\n",
    "        userId = rating[1].split(':')[0]\n",
    "        movieId = rating[2].split(':')[0]\n",
    "        predicted_rating = predictor.predict([np.array([int(userId), int(movieId)])])\n",
    "        print(f'    Actual Rating: \\t{rating[0]}')\n",
    "        print(f\"    Predicted Rating: \\t{predicted_rating['predictions'][0]['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e49bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1917de1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
